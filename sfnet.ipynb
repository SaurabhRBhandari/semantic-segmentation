{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/SaurabhRBhandari/semantic-segmentation/blob/main/sfnet.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn, Tensor\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"2 Layer No Expansion Block\n",
    "    \"\"\"\n",
    "    expansion: int = 1\n",
    "    def __init__(self, c1, c2, s=1, downsample= None) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(c1, c2, 3, s, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(c2)\n",
    "        self.conv2 = nn.Conv2d(c2, c2, 3, 1, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(c2)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.downsample is not None: identity = self.downsample(x)\n",
    "        out += identity\n",
    "        return F.relu(out)\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"3 Layer 4x Expansion Block\n",
    "    \"\"\"\n",
    "    expansion: int = 4\n",
    "    def __init__(self, c1, c2, s=1, downsample=None) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(c1, c2, 1, 1, 0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(c2)\n",
    "        self.conv2 = nn.Conv2d(c2, c2, 3, s, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(c2)\n",
    "        self.conv3 = nn.Conv2d(c2, c2 * self.expansion, 1, 1, 0, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(c2 * self.expansion)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        if self.downsample is not None: identity = self.downsample(x)\n",
    "        out += identity\n",
    "        return F.relu(out)\n",
    "\n",
    "\n",
    "resnet_settings = {\n",
    "    '18': [BasicBlock, [2, 2, 2, 2], [64, 128, 256, 512]],\n",
    "    '34': [BasicBlock, [3, 4, 6, 3], [64, 128, 256, 512]],\n",
    "    '50': [Bottleneck, [3, 4, 6, 3], [256, 512, 1024, 2048]],\n",
    "    '101': [Bottleneck, [3, 4, 23, 3], [256, 512, 1024, 2048]],\n",
    "    '152': [Bottleneck, [3, 8, 36, 3], [256, 512, 1024, 2048]]\n",
    "}\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, model_name: str = '50') -> None:\n",
    "        super().__init__()\n",
    "        assert model_name in resnet_settings.keys(), f\"ResNet model name should be in {list(resnet_settings.keys())}\"\n",
    "        block, depths, channels = resnet_settings[model_name]\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.channels = channels\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, 7, 2, 3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
    "        self.maxpool = nn.MaxPool2d(3, 2, 1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, depths[0], s=1)\n",
    "        self.layer2 = self._make_layer(block, 128, depths[1], s=2)\n",
    "        self.layer3 = self._make_layer(block, 256, depths[2], s=2)\n",
    "        self.layer4 = self._make_layer(block, 512, depths[3], s=2)\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, planes, depth, s=1) -> nn.Sequential:\n",
    "        downsample = None\n",
    "        if s != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion, 1, s, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion)\n",
    "            )\n",
    "        layers = nn.Sequential(\n",
    "            block(self.inplanes, planes, s, downsample),\n",
    "            *[block(planes * block.expansion, planes) for _ in range(1, depth)]\n",
    "        )\n",
    "        self.inplanes = planes * block.expansion\n",
    "        return layers\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.maxpool(F.relu(self.bn1(self.conv1(x))))   # [1, 64, H/4, W/4]\n",
    "        x1 = self.layer1(x)  # [1, 64/256, H/4, W/4]   \n",
    "        x2 = self.layer2(x1)  # [1, 128/512, H/8, W/8]\n",
    "        x3 = self.layer3(x2)  # [1, 256/1024, H/16, W/16]\n",
    "        x4 = self.layer4(x3)  # [1, 512/2048, H/32, W/32]\n",
    "        return x1, x2, x3, x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModule(nn.Sequential):\n",
    "    def __init__(self, c1, c2, k, s=1, p=0, d=1, g=1):\n",
    "        super().__init__(\n",
    "            nn.Conv2d(c1, c2, k, s, p, d, g, bias=False),\n",
    "            nn.BatchNorm2d(c2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "class PPM(nn.Module):\n",
    "    \"\"\"Pyramid Pooling Module in PSPNet\n",
    "    \"\"\"\n",
    "    def __init__(self, c1, c2=128, scales=(1, 2, 3, 6)):\n",
    "        super().__init__()\n",
    "        self.stages = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d(scale),\n",
    "                ConvModule(c1, c2, 1)\n",
    "            )\n",
    "        for scale in scales])\n",
    "\n",
    "        self.bottleneck = ConvModule(c1 + c2 * len(scales), c2, 3, 1, 1)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outs = []\n",
    "        for stage in self.stages:\n",
    "            outs.append(F.interpolate(stage(x), size=x.shape[-2:], mode='bilinear', align_corners=True))\n",
    "\n",
    "        outs = [x] + outs[::-1]\n",
    "        out = self.bottleneck(torch.cat(outs, dim=1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlignedModule(nn.Module):\n",
    "    def __init__(self, c1, c2, k=3):\n",
    "        super().__init__()\n",
    "        self.down_h = nn.Conv2d(c1, c2, 1, bias=False)\n",
    "        self.down_l = nn.Conv2d(c1, c2, 1, bias=False)\n",
    "        self.flow_make = nn.Conv2d(c2 * 2, 2, k, 1, 1, bias=False)\n",
    "\n",
    "    def forward(self, low_feature: Tensor, high_feature: Tensor) -> Tensor:\n",
    "        high_feature_origin = high_feature\n",
    "        H, W = low_feature.shape[-2:]\n",
    "        low_feature = self.down_l(low_feature)\n",
    "        high_feature = self.down_h(high_feature)\n",
    "        high_feature = F.interpolate(high_feature, size=(H, W), mode='bilinear', align_corners=True)\n",
    "        flow = self.flow_make(torch.cat([high_feature, low_feature], dim=1))\n",
    "        high_feature = self.flow_warp(high_feature_origin, flow, (H, W))\n",
    "        return high_feature\n",
    "\n",
    "    def flow_warp(self, x: Tensor, flow: Tensor, size: tuple) -> Tensor:\n",
    "        # norm = torch.tensor(size).reshape(1, 1, 1, -1)\n",
    "        norm = torch.tensor([[[[*size]]]]).type_as(x).to(x.device)\n",
    "        H = torch.linspace(-1.0, 1.0, size[0]).view(-1, 1).repeat(1, size[1])\n",
    "        W = torch.linspace(-1.0, 1.0, size[1]).repeat(size[0], 1)\n",
    "        grid = torch.cat((W.unsqueeze(2), H.unsqueeze(2)), dim=2)\n",
    "        grid = grid.repeat(x.shape[0], 1, 1, 1).type_as(x).to(x.device)\n",
    "        grid = grid + flow.permute(0, 2, 3, 1) / norm\n",
    "        output = F.grid_sample(x, grid, align_corners=False)\n",
    "        return output\n",
    "\n",
    "\n",
    "class SFHead(nn.Module):\n",
    "    def __init__(self, in_channels, channel=256, num_classes=19, scales=(1, 2, 3, 6)):\n",
    "        super().__init__()\n",
    "        self.ppm = PPM(in_channels[-1], channel, scales)\n",
    "\n",
    "        self.fpn_in = nn.ModuleList([])\n",
    "        self.fpn_out = nn.ModuleList([])\n",
    "        self.fpn_out_align = nn.ModuleList([])\n",
    "\n",
    "        for in_ch in in_channels[:-1]:\n",
    "            self.fpn_in.append(ConvModule(in_ch, channel, 1))\n",
    "            self.fpn_out.append(ConvModule(channel, channel, 3, 1, 1))\n",
    "            self.fpn_out_align.append(AlignedModule(channel, channel//2))\n",
    "\n",
    "        self.bottleneck = ConvModule(len(in_channels) * channel, channel, 3, 1, 1)\n",
    "        self.dropout = nn.Dropout2d(0.1)\n",
    "        self.conv_seg = nn.Conv2d(channel, num_classes, 1)\n",
    "\n",
    "    def forward(self, features: list) -> Tensor:\n",
    "        f = self.ppm(features[-1])\n",
    "        fpn_features = [f]\n",
    "\n",
    "        for i in reversed(range(len(features) - 1)):\n",
    "            feature = self.fpn_in[i](features[i])\n",
    "            f = feature + self.fpn_out_align[i](feature, f)\n",
    "            fpn_features.append(self.fpn_out[i](f))\n",
    "\n",
    "        fpn_features.reverse()\n",
    "\n",
    "        for i in range(1, len(fpn_features)):\n",
    "            fpn_features[i] = F.interpolate(fpn_features[i], size=fpn_features[0].shape[-2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        output = self.bottleneck(torch.cat(fpn_features, dim=1))\n",
    "        output = self.conv_seg(self.dropout(output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SFNet(nn.Module):\n",
    "    def __init__(self,num_classes=19):\n",
    "        super().__init__()\n",
    "        self.backbone=ResNet()\n",
    "        self.head=SFHead(self.backbone.channels,256,num_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        outs=self.backbone(x)\n",
    "        out=self.head(outs)\n",
    "        out = F.interpolate(out, size=x.shape[-2:], mode='bilinear', align_corners=True)\n",
    "        return out \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─ResNet: 1-1                            [-1, 256, 64, 64]         --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 128, 128]        9,408\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 64, 128, 128]        128\n",
      "|    └─MaxPool2d: 2-3                    [-1, 64, 64, 64]          --\n",
      "|    └─Sequential: 2-4                   [-1, 256, 64, 64]         --\n",
      "|    |    └─Bottleneck: 3-1              [-1, 256, 64, 64]         75,008\n",
      "|    |    └─Bottleneck: 3-2              [-1, 256, 64, 64]         70,400\n",
      "|    |    └─Bottleneck: 3-3              [-1, 256, 64, 64]         70,400\n",
      "|    └─Sequential: 2-5                   [-1, 512, 32, 32]         --\n",
      "|    |    └─Bottleneck: 3-4              [-1, 512, 32, 32]         379,392\n",
      "|    |    └─Bottleneck: 3-5              [-1, 512, 32, 32]         280,064\n",
      "|    |    └─Bottleneck: 3-6              [-1, 512, 32, 32]         280,064\n",
      "|    |    └─Bottleneck: 3-7              [-1, 512, 32, 32]         280,064\n",
      "|    └─Sequential: 2-6                   [-1, 1024, 16, 16]        --\n",
      "|    |    └─Bottleneck: 3-8              [-1, 1024, 16, 16]        1,512,448\n",
      "|    |    └─Bottleneck: 3-9              [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-10             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-11             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-12             [-1, 1024, 16, 16]        1,117,184\n",
      "|    |    └─Bottleneck: 3-13             [-1, 1024, 16, 16]        1,117,184\n",
      "|    └─Sequential: 2-7                   [-1, 2048, 8, 8]          --\n",
      "|    |    └─Bottleneck: 3-14             [-1, 2048, 8, 8]          6,039,552\n",
      "|    |    └─Bottleneck: 3-15             [-1, 2048, 8, 8]          4,462,592\n",
      "|    |    └─Bottleneck: 3-16             [-1, 2048, 8, 8]          4,462,592\n",
      "├─SFHead: 1-2                            [-1, 19, 64, 64]          --\n",
      "|    └─PPM: 2-8                          [-1, 256, 8, 8]           --\n",
      "|    |    └─ConvModule: 3-17             [-1, 256, 8, 8]           7,078,400\n",
      "|    └─ModuleList: 2                     []                        --\n",
      "|    |    └─ConvModule: 3-18             [-1, 256, 16, 16]         262,656\n",
      "|    └─ModuleList: 2                     []                        --\n",
      "|    |    └─AlignedModule: 3-19          [-1, 256, 16, 16]         70,144\n",
      "|    └─ModuleList: 2                     []                        --\n",
      "|    |    └─ConvModule: 3-20             [-1, 256, 16, 16]         590,336\n",
      "|    └─ModuleList: 2                     []                        --\n",
      "|    |    └─ConvModule: 3-21             [-1, 256, 32, 32]         131,584\n",
      "|    └─ModuleList: 2                     []                        --\n",
      "|    |    └─AlignedModule: 3-22          [-1, 256, 32, 32]         70,144\n",
      "|    └─ModuleList: 2                     []                        --\n",
      "|    |    └─ConvModule: 3-23             [-1, 256, 32, 32]         590,336\n",
      "|    └─ModuleList: 2                     []                        --\n",
      "|    |    └─ConvModule: 3-24             [-1, 256, 64, 64]         66,048\n",
      "|    └─ModuleList: 2                     []                        --\n",
      "|    |    └─AlignedModule: 3-25          [-1, 256, 64, 64]         70,144\n",
      "|    └─ModuleList: 2                     []                        --\n",
      "|    |    └─ConvModule: 3-26             [-1, 256, 64, 64]         590,336\n",
      "|    └─ConvModule: 2-9                   [-1, 256, 64, 64]         --\n",
      "|    |    └─Conv2d: 3-27                 [-1, 256, 64, 64]         2,359,296\n",
      "|    |    └─BatchNorm2d: 3-28            [-1, 256, 64, 64]         512\n",
      "|    |    └─ReLU: 3-29                   [-1, 256, 64, 64]         --\n",
      "|    └─Dropout2d: 2-10                   [-1, 256, 64, 64]         --\n",
      "|    └─Conv2d: 2-11                      [-1, 19, 64, 64]          4,883\n",
      "==========================================================================================\n",
      "Total params: 35,392,851\n",
      "Trainable params: 35,392,851\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 19.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 256.99\n",
      "Params size (MB): 135.01\n",
      "Estimated Total Size (MB): 392.75\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─ResNet: 1-1                            [-1, 256, 64, 64]         --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 128, 128]        9,408\n",
       "|    └─BatchNorm2d: 2-2                  [-1, 64, 128, 128]        128\n",
       "|    └─MaxPool2d: 2-3                    [-1, 64, 64, 64]          --\n",
       "|    └─Sequential: 2-4                   [-1, 256, 64, 64]         --\n",
       "|    |    └─Bottleneck: 3-1              [-1, 256, 64, 64]         75,008\n",
       "|    |    └─Bottleneck: 3-2              [-1, 256, 64, 64]         70,400\n",
       "|    |    └─Bottleneck: 3-3              [-1, 256, 64, 64]         70,400\n",
       "|    └─Sequential: 2-5                   [-1, 512, 32, 32]         --\n",
       "|    |    └─Bottleneck: 3-4              [-1, 512, 32, 32]         379,392\n",
       "|    |    └─Bottleneck: 3-5              [-1, 512, 32, 32]         280,064\n",
       "|    |    └─Bottleneck: 3-6              [-1, 512, 32, 32]         280,064\n",
       "|    |    └─Bottleneck: 3-7              [-1, 512, 32, 32]         280,064\n",
       "|    └─Sequential: 2-6                   [-1, 1024, 16, 16]        --\n",
       "|    |    └─Bottleneck: 3-8              [-1, 1024, 16, 16]        1,512,448\n",
       "|    |    └─Bottleneck: 3-9              [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-10             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-11             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-12             [-1, 1024, 16, 16]        1,117,184\n",
       "|    |    └─Bottleneck: 3-13             [-1, 1024, 16, 16]        1,117,184\n",
       "|    └─Sequential: 2-7                   [-1, 2048, 8, 8]          --\n",
       "|    |    └─Bottleneck: 3-14             [-1, 2048, 8, 8]          6,039,552\n",
       "|    |    └─Bottleneck: 3-15             [-1, 2048, 8, 8]          4,462,592\n",
       "|    |    └─Bottleneck: 3-16             [-1, 2048, 8, 8]          4,462,592\n",
       "├─SFHead: 1-2                            [-1, 19, 64, 64]          --\n",
       "|    └─PPM: 2-8                          [-1, 256, 8, 8]           --\n",
       "|    |    └─ConvModule: 3-17             [-1, 256, 8, 8]           7,078,400\n",
       "|    └─ModuleList: 2                     []                        --\n",
       "|    |    └─ConvModule: 3-18             [-1, 256, 16, 16]         262,656\n",
       "|    └─ModuleList: 2                     []                        --\n",
       "|    |    └─AlignedModule: 3-19          [-1, 256, 16, 16]         70,144\n",
       "|    └─ModuleList: 2                     []                        --\n",
       "|    |    └─ConvModule: 3-20             [-1, 256, 16, 16]         590,336\n",
       "|    └─ModuleList: 2                     []                        --\n",
       "|    |    └─ConvModule: 3-21             [-1, 256, 32, 32]         131,584\n",
       "|    └─ModuleList: 2                     []                        --\n",
       "|    |    └─AlignedModule: 3-22          [-1, 256, 32, 32]         70,144\n",
       "|    └─ModuleList: 2                     []                        --\n",
       "|    |    └─ConvModule: 3-23             [-1, 256, 32, 32]         590,336\n",
       "|    └─ModuleList: 2                     []                        --\n",
       "|    |    └─ConvModule: 3-24             [-1, 256, 64, 64]         66,048\n",
       "|    └─ModuleList: 2                     []                        --\n",
       "|    |    └─AlignedModule: 3-25          [-1, 256, 64, 64]         70,144\n",
       "|    └─ModuleList: 2                     []                        --\n",
       "|    |    └─ConvModule: 3-26             [-1, 256, 64, 64]         590,336\n",
       "|    └─ConvModule: 2-9                   [-1, 256, 64, 64]         --\n",
       "|    |    └─Conv2d: 3-27                 [-1, 256, 64, 64]         2,359,296\n",
       "|    |    └─BatchNorm2d: 3-28            [-1, 256, 64, 64]         512\n",
       "|    |    └─ReLU: 3-29                   [-1, 256, 64, 64]         --\n",
       "|    └─Dropout2d: 2-10                   [-1, 256, 64, 64]         --\n",
       "|    └─Conv2d: 2-11                      [-1, 19, 64, 64]          4,883\n",
       "==========================================================================================\n",
       "Total params: 35,392,851\n",
       "Trainable params: 35,392,851\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 19.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.75\n",
       "Forward/backward pass size (MB): 256.99\n",
       "Params size (MB): 135.01\n",
       "Estimated Total Size (MB): 392.75\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=SFNet()\n",
    "summary(model,(3,256,256),device=\"cpu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
